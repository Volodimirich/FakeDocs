# Model
model:
# "t5-v1_1-small", "t5-v1_1-large", "gpt2"
  model_name: "ai-forever/rugpt3large_based_on_gpt2"
  tokenizer_name: "ai-forever/rugpt3large_based_on_gpt2"
  local_path: './result_GPT3_Sber_sep_token/checkpoint-155'
  use_local: True
  path_save_model: ""
  input_max_length: 512
  target_max_length: 512
  total_samples: 2
  batch_size: 2
  predict_param:
    do_sample: True
    num_beams: 2
    temperature: 1.5
    top_p: 0.9
    max_length: 700

result:
  launch_description: "rugpt3large_based_on_gpt2_pretrained_155"
  path_to_save_result: "./result"
  save_examples: True
  number_examples_batch: 3
  gpt_postprocessing: True

# Dataset
dataset:
  # file_path: 'D:\\projects_andrey\\datasets_made\\fulldocs_txt.txt'
  save_dir: 'data'
  # full_data - с сайта, part_data - размеченная с hugging face
  dataset_name: "made_data"
  block_size: 128
  mlm: False

  # Gdown помойка, надеюсь они починять folder_download
  gdrive_dict:
    full_data: https://drive.google.com/uc?id=1NCjkrgzKsOpwxHUMW-x0KQzSZbpm6g9P
    part_data:
      train: https://drive.google.com/uc?id=1x_Sho7xYqsJPvB8zDZWudSO4WsifhJfs
      test: https://drive.google.com/uc?id=1R-k_Osj7NFi1rEvx0citRIbzXT7IzIAc
      val: https://drive.google.com/uc?id=1RBoqgf2d5cGUNne6F7ZWZd4GUwQpSqjZ

